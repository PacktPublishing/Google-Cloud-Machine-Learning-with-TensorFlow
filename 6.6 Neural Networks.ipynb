{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Neural Networks with TensorFlow Estimator API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: 0728281a-f017-4fe8-bc8c-4d69b962fb41\n",
      "Query executing: 1.16s\n",
      "Query complete after 1.48s\n"
     ]
    }
   ],
   "source": [
    "%%bigquery flights_df --project tensorflow-ml-course --verbose\n",
    "\n",
    "SELECT \n",
    "\n",
    "  -- Departure delay\n",
    "  departure_delay,\n",
    "    \n",
    "  -- Distance\n",
    "  distance,\n",
    "\n",
    "  -- Airlines\n",
    "  airline,\n",
    "    \n",
    "  -- Airports \n",
    "  departure_airport,\n",
    "  arrival_airport, \n",
    "\n",
    "  -- Date information\n",
    "  CAST(EXTRACT(DAYOFWEEK FROM departure_date) AS STRING) as departure_weekday,\n",
    "  CAST(EXTRACT(MONTH FROM departure_date) AS STRING) as departure_month,\n",
    "\n",
    "  -- Target column\n",
    "  CASE WHEN (arrival_delay >= 15) THEN 1 ELSE 0 END as delayed\n",
    "  \n",
    "  FROM ( \n",
    "    \n",
    "    -- Inner Query\n",
    "    SELECT\n",
    "      \n",
    "      departure_delay,\n",
    "      ROUND(ST_DISTANCE(ST_GEOGPOINT(departure_lon, departure_lat), ST_GEOGPOINT(arrival_lon, arrival_lat))/1000) as distance,\n",
    "      airline,\n",
    "      arrival_airport,\n",
    "      departure_airport,\n",
    "      PARSE_DATE(\"%Y-%m-%d\", date) AS departure_date,\n",
    "      \n",
    "      arrival_delay\n",
    "      \n",
    "      \n",
    "    FROM\n",
    "      `bigquery-samples.airline_ontime_data.flights`\n",
    "    WHERE date >= '2009-01-01' \n",
    "    AND date <= '2009-01-31'\n",
    "    AND departure_delay > 0\n",
    "    \n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: 3d6caff1-a3b7-4c0c-bb52-eb6c4af5edb2\n",
      "Query executing: 0.86s\n",
      "Query complete after 1.17s\n"
     ]
    }
   ],
   "source": [
    "%%bigquery high_traffic_airports --project tensorflow-ml-course --verbose\n",
    "\n",
    "SELECT * FROM\n",
    " \n",
    " (SELECT departure_airport as airport_code,\n",
    "  COUNT(*) as flights\n",
    "  \n",
    "  FROM\n",
    "    `bigquery-samples.airline_ontime_data.flights`    \n",
    "  \n",
    "  WHERE date >= '2009-01-01' \n",
    "    AND date <= '2009-12-31'\n",
    "    \n",
    "  GROUP BY departure_airport\n",
    "  ORDER BY airport_code)\n",
    "\n",
    "WHERE flights > 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: 6f2d5976-22cd-439e-9e29-dba45406ee0f\n",
      "Query executing: 0.77s\n",
      "Query complete after 1.05s\n"
     ]
    }
   ],
   "source": [
    "%%bigquery airline_codes --project tensorflow-ml-course --verbose\n",
    "\n",
    "SELECT DISTINCT(airline)\n",
    "  \n",
    "FROM\n",
    "    `bigquery-samples.airline_ontime_data.flights`\n",
    "    \n",
    "WHERE date >= '2009-01-01' \n",
    "    AND date <= '2009-12-31'\n",
    "    \n",
    "ORDER BY airline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188843, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departure_delay</th>\n",
       "      <th>distance</th>\n",
       "      <th>airline</th>\n",
       "      <th>departure_airport</th>\n",
       "      <th>arrival_airport</th>\n",
       "      <th>departure_weekday</th>\n",
       "      <th>departure_month</th>\n",
       "      <th>delayed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13106</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>SEA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107040</th>\n",
       "      <td>11.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>DTW</td>\n",
       "      <td>ORD</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125472</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>CO</td>\n",
       "      <td>FLL</td>\n",
       "      <td>IAH</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12684</th>\n",
       "      <td>4.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>MQ</td>\n",
       "      <td>SAN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150694</th>\n",
       "      <td>13.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>RDU</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        departure_delay  distance airline departure_airport arrival_airport  \\\n",
       "13106              34.0    1537.0      AS               SEA             LAX   \n",
       "107040             11.0     376.0      NW               DTW             ORD   \n",
       "125472              2.0    1552.0      CO               FLL             IAH   \n",
       "12684               4.0     176.0      MQ               SAN             LAX   \n",
       "150694             13.0     572.0      DL               ATL             RDU   \n",
       "\n",
       "       departure_weekday departure_month  delayed  \n",
       "13106                  6               1        1  \n",
       "107040                 2               1        0  \n",
       "125472                 5               1        0  \n",
       "12684                  3               1        0  \n",
       "150694                 7               1        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df.sample(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Testing-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = flights_df.sample(frac=0.8,random_state=123)\n",
    "test_df = flights_df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151074 train examples\n",
      "37769 test examples\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df), 'train examples')\n",
    "print(len(test_df), 'test examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.599999999999994 % delay in total dataset\n",
      "47.599999999999994 % delay in total dataset\n",
      "47.4 % delay in total dataset\n"
     ]
    }
   ],
   "source": [
    "print(round(flights_df.delayed.mean(),3)*100, '% delay in total dataset')\n",
    "print(round(train_df.delayed.mean(),3)*100, '% delay in total dataset')\n",
    "print(round(test_df.delayed.mean(),3)*100, '% delay in total dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input pipeline using tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a tf.data.Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Batch Dataset from a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df.pop('delayed')\n",
    "test_y = test_df.pop('delayed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, shuffle=True, batch_size=batch_size):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    features = features.copy()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Features using tf.feature_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define bins: This time we are not binning the numeric variables, because we want the network to learn the non-linear effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_voc = high_traffic_airports['airport_code']\n",
    "airlines_voc = airline_codes['airline']\n",
    "weekdays_voc = ['1', '2', '3', '4', '5', '6', '7']\n",
    "months_voc = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# numeric columns\n",
    "distance = tf.feature_column.numeric_column(\"distance\")\n",
    "feature_columns.append(distance)\n",
    "\n",
    "departure_delay = tf.feature_column.numeric_column(\"departure_delay\")\n",
    "feature_columns.append(departure_delay)\n",
    "\n",
    "# categorical columns\n",
    "arrival_airports = tf.feature_column.categorical_column_with_vocabulary_list('arrival_airport', airports_voc)\n",
    "arrival_airports_dummy = tf.feature_column.indicator_column(arrival_airports)\n",
    "feature_columns.append(arrival_airports_dummy)\n",
    "\n",
    "departure_airports = tf.feature_column.categorical_column_with_vocabulary_list('departure_airport', airports_voc)\n",
    "departure_airports_dummy = tf.feature_column.indicator_column(departure_airports)\n",
    "feature_columns.append(departure_airports_dummy)\n",
    "\n",
    "airlines = tf.feature_column.categorical_column_with_vocabulary_list('airline', airlines_voc)\n",
    "airlines_dummy = tf.feature_column.indicator_column(airlines)\n",
    "feature_columns.append(airlines_dummy)\n",
    "\n",
    "weekdays = tf.feature_column.categorical_column_with_vocabulary_list('departure_weekday', weekdays_voc)\n",
    "weekdays_dummy = tf.feature_column.indicator_column(weekdays)\n",
    "feature_columns.append(weekdays_dummy)\n",
    "\n",
    "#months = tf.feature_column.categorical_column_with_vocabulary_list('departure_month', months_voc)\n",
    "#months_dummy = tf.feature_column.indicator_column(months)\n",
    "#feature_columns.append(months_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1022 16:06:09.947477 140681593272064 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2655: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1022 16:06:09.951304 140681593272064 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4215: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "W1022 16:06:09.952152 140681593272064 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4270: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 1.70e+01, 1.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 1.51e+03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch = next(iter(input_fn(train_df, train_y, shuffle=False)))[0]\n",
    "\n",
    "feature_layer_demo = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "feature_layer_demo(example_batch).numpy()[:5][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model using TF.Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of Estimator**\n",
    "\n",
    "Estimator and Keras are both high level APIs for model abstraction in TensorFlow. TF.estimator provides some capabilities that are currently not available for tf.keras:\n",
    "\n",
    "- Parameter server based training\n",
    "- Full TFX integration.\n",
    "\n",
    "**Important:** Applications with Estimators require to separate the data input pipeline from the actual model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-made Estimators**\n",
    "\n",
    "- tf.estimator.DNNClassifier (Deep models with multi-class classification) \n",
    "- tf.estimator.LinearClassifier (Classifiers based on linear models)\n",
    "- tf.estimator.LinearRegressor (Linear regression problems)\n",
    "- tf.estimator.DNNLinearCombinedClassifier (for wide & deep models)\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an ANN with 2 hidden layers with 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    # Two hidden layers of 10 nodes each.\n",
    "    hidden_units=[10, 10],\n",
    "    # The model must choose between 2 classes.\n",
    "    n_classes=2,\n",
    "    optimizer='Adam',\n",
    "    model_dir='logs/DNN/')\n",
    "\n",
    "# By default loss is calculated using softmax cross entropy for the DNNClassifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1022 16:06:09.992830 140681593272064 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W1022 16:06:12.809975 140681593272064 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/head/base_head.py:574: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7ff28e0f9eb8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train_df, train_y, shuffle=True),\n",
    "    steps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1022 16:15:53.694638 140681593272064 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 0.837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test_df, test_y, shuffle=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
